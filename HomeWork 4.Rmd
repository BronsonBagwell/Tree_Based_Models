---
title: "HomeWork 4"
author: "Bronson Bagwell"
date: "2024-01-31"
output: html_document
---

```{r, results='hide', warning=FALSE, message=FALSE}
library(party)
library(caret)
library(randomForest)
```

```{r, results='hide'}
data <- read.csv("GraduateAdmission.csv")
data <- subset(data, select = -Serial.No.)

str(data) 
names(data)
```

# 1. Prepare the data by converting some of the features to factors.

```{r}
data$UnivRating <- as.factor(data$UnivRating)
data$Research <- as.factor(data$Research)
data$Admit <- as.factor(data$Admit)
```

# 2. Split the data into a 80% training set and a 20% test set. Use set.seed (7332.01) for reproducibility.

```{r}
set.seed(7332.01)
Index <- createDataPartition(data$Admit,p=0.8,list=FALSE)
trdata <- data[Index,]  
tsdata <- data[-Index,] 
head(trdata)
head(tsdata) 

names(data)
```

# 3. Fit Classification Tree to the training dataset and answer the following questions.

```{r}
clatree <- ctree(Admit~.,trdata)
print(clatree)

    # Plot the classification tree and interpret the results.

plot(clatree)
plot(clatree,type="simple")
```

Interpret

This conditional inference tree predicts admission outcomes based on seven input features (GRE, TOEFL, UnivRating, SOP, LOR, CGPA, Research) with 320 observations. The primary split is on CGPA at 8.03. For CGPA â‰¤ 8.03, it considers LOR, splitting at 2.5, resulting in two terminal nodes. For CGPA > 8.03, it further splits on CGPA at 8.5, creating two more terminal nodes. The model predicts "Admit" with specific sample sizes in each terminal node.

```{r}

    #Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test overall accuracy. misclassification (error rate), sensitivity and specificity?

pred_clatree <-predict(clatree, tsdata) 
conf_clatree<-table(Predicted=pred_clatree,Actual=tsdata$Admit) 
conf_clatree

    #Accuracy
Accuracy <- sum(diag(conf_clatree))/sum(conf_clatree)  
Accuracy
    #Misclassification (Error Rate)
test_ercltree <- 1-sum(diag(conf_clatree))/sum(conf_clatree )  
test_ercltree
    #Sensitivity
sensitivity <- conf_clatree[1, 1] / sum(conf_clatree[1, ])
sensitivity
    #Specificty
specificity <- conf_clatree[2, 2] / sum(conf_clatree[2, ])
specificity
```

# 4. Fit random forests for classification to the training data and answer the following questions.
```{r}
clarf <- randomForest(Admit~.,trdata,importance=TRUE) 

    #Plot the random forest. Describe the plot.
plot(clarf,main="Random Forest Error rate vs ntrees" )  
legend(450,0.6,colnames(clarf$err.rate),col=1:3,cex=0.8,fill=1:3)

    #Use varImpPlot() function to determine which variables are most important. List the top 3 important features.
varImpPlot(clarf,main="Random Forest-Variable Importance" )
importance(clarf)
```
Describe the plot
  
  This is a plot describing Error vs ntrees. Out of bag Error is relativly Steady. As ntrees increases Non-Admit error rate increases and then levels out at around ntrees=100. As ntrees increases Admit error rate decreases and then levels out at around ntrees=180. 

1. CGPA

2. GRE

3. SOP

```{r}
    #Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test overall accuracy and misclassification (error rate), sensitivity and specificity?
pred_clarf  <-predict(clarf , tsdata) 
conf_clarf <-table(Predicted=pred_clarf ,Actual=tsdata$Admit) 
conf_clarf

    #Accuracy
Accuracy <- sum(diag(conf_clarf))/sum(conf_clarf)   
Accuracy
    #Misclassification (Error Rate)
test_erclarf <- 1-sum(diag(conf_clarf ))/sum(conf_clarf )
test_erclarf
    #Sensitivity
sensitivity <- conf_clarf[1, 1] / sum(conf_clarf[1, ])
sensitivity
    #Specificty
specificity <- conf_clarf[2, 2] / sum(conf_clarf[2, ])
specificity

```

# 5. Fit Bagging for classification to the training data and answer the following questions

```{r}
clabag <- randomForest(Admit~.,trdata,mtry=12,importance=TRUE)  
print(clabag)

    #Plot the Bagging model. Describe the plot. 
plot(clabag,main="Bagging Error rate vs ntrees")
legend(450,0.35,colnames(clarf$err.rate),col=1:3,cex=0.8,fill=1:3)

    #Use the varImpPlot() function to determine which variables are most important.
varImpPlot(clabag, main="Bagging-Variable Importance ") 
importance(clabag)
```
Describe the plot
  
  This is a plot describing Error vs ntrees. Out of bag Error is relativly Steady with a slight decrease as ntrees increases. As ntrees increases Non-Admit error rate slightly increases and then levels. As ntrees increases Admit error rate is decreases then levels out at around ntrees=90

1. CGPA

2. GRE

3. LOR

```{r}
    #Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test overall accuracy and misclassification (error rate), sensitivity and specificity?
pred_clabag <-predict(clabag, tsdata) 
conf_clabag<-table(Predicted=pred_clabag,Actual=tsdata$Admit) 
conf_clabag

    #Accuracy
sum(diag(conf_clabag))/sum(conf_clabag)   
    #Misclassification (Error Rate)
test_erclabag <- 1-sum(diag(conf_clabag))/sum(conf_clabag)  # test error rate
test_erclabag
    #Sensitivity
sensitivity <- conf_clabag[1, 1] / sum(conf_clabag[1, ])
sensitivity
    #Specificty
specificity <- conf_clabag[2, 2] / sum(conf_clabag[2, ])
specificity

```

# 6. What was the misclassification error you found for the test data in Homework 3?

0.125

# 7. Compare the misclassification error from the decision tree, Random Forest, Random Forest-Bagging and the logistic model from homework 3. Which classification method is better?

Logistic Model is at .1125 with the lowest Error, Making it the better option.

```{r}
logistic_model <- 0.1125
Test_erclacomp <- data.frame(test_ercltree, test_erclabag, test_erclarf, logistic_model)
Test_erclacomp
```


# 8. Write the names of each team who worked together. If you do it alone, just write your name.

Bronson Bagwell